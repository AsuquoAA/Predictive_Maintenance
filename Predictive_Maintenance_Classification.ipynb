{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ successfully loaded SE.txt\n",
      "✅ successfully loaded PS1.txt\n",
      "✅ successfully loaded TS4.txt\n",
      "✅ successfully loaded PS2.txt\n",
      "✅ successfully loaded PS3.txt\n",
      "✅ successfully loaded TS3.txt\n",
      "✅ successfully loaded VS1.txt\n",
      "✅ successfully loaded TS2.txt\n",
      "✅ successfully loaded PS6.txt\n",
      "✅ successfully loaded PS4.txt\n",
      "documentation.txt is not in csv format❌\n",
      "✅ successfully loaded TS1.txt\n",
      "✅ successfully loaded PS5.txt\n",
      "✅ successfully loaded CP.txt\n",
      "✅ successfully loaded CE.txt\n",
      "description.txt is not in csv format❌\n",
      "✅ successfully loaded EPS1.txt\n",
      "✅ successfully loaded FS1.txt\n",
      "✅ successfully loaded FS2.txt\n",
      "✅ successfully loaded profile.txt\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    zip_path = 'condition+monitoring+of+hydraulic+systems.zip'\n",
    "    extract_path = './data'\n",
    "\n",
    "    with zipfile.ZipFile(zip_path,'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    dataframes = {}\n",
    "    for file in os.listdir(extract_path):\n",
    "        file_path =  os.path.join(extract_path,file)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter='\\t',header=None)\n",
    "            dataframes[file] = df\n",
    "            print(f'✅ successfully loaded {file}')\n",
    "\n",
    "        except UnicodeDecodeError:\n",
    "            print(f'{file} is not in csv format❌')  \n",
    "    return dataframes\n",
    "\n",
    "dataframes = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE.txt has 0 missing values\n",
      "PS1.txt has 0 missing values\n",
      "TS4.txt has 0 missing values\n",
      "PS2.txt has 0 missing values\n",
      "PS3.txt has 0 missing values\n",
      "TS3.txt has 0 missing values\n",
      "VS1.txt has 0 missing values\n",
      "TS2.txt has 0 missing values\n",
      "PS6.txt has 0 missing values\n",
      "PS4.txt has 0 missing values\n",
      "TS1.txt has 0 missing values\n",
      "PS5.txt has 0 missing values\n",
      "CP.txt has 0 missing values\n",
      "CE.txt has 0 missing values\n",
      "EPS1.txt has 0 missing values\n",
      "FS1.txt has 0 missing values\n",
      "FS2.txt has 0 missing values\n",
      "profile.txt has 0 missing values\n",
      "Convert data to floats\n",
      "processing.....\n",
      "SE.txt has been converted\n",
      "PS1.txt has been converted\n",
      "TS4.txt has been converted\n",
      "PS2.txt has been converted\n",
      "PS3.txt has been converted\n",
      "TS3.txt has been converted\n",
      "VS1.txt has been converted\n",
      "TS2.txt has been converted\n",
      "PS6.txt has been converted\n",
      "PS4.txt has been converted\n",
      "TS1.txt has been converted\n",
      "PS5.txt has been converted\n",
      "CP.txt has been converted\n",
      "CE.txt has been converted\n",
      "EPS1.txt has been converted\n",
      "FS1.txt has been converted\n",
      "FS2.txt has been converted\n",
      "profile.txt has been converted\n"
     ]
    }
   ],
   "source": [
    "#Preparing data for sql database\n",
    "def rename_profile_columns():\n",
    "    for key, value in dataframes.items():\n",
    "        if key == 'profile.txt':\n",
    "            value.columns = ['Cooler_Condition','Valve_Condition','Pump_Leakage','Accumulator_Condition','Stable_Flag']\n",
    "\n",
    "rename_profile_columns()\n",
    "\n",
    "def reindex_rows():\n",
    "    for key, value in dataframes.items():\n",
    "        index = range(1,(len(value+1)))\n",
    "        dataframes[key] = value.reindex()\n",
    "\n",
    "reindex_rows()\n",
    "\n",
    "def check_for_missing_values():\n",
    "    for key,value in dataframes.items():\n",
    "        number_missing = value.isnull().sum().sum()\n",
    "        print(f'{key} has {number_missing} missing values')\n",
    "\n",
    "check_for_missing_values()\n",
    "\n",
    "def convert_data_types():\n",
    "    \"\"\"Converts all columns to float if possible.\"\"\"\n",
    "    print('Convert data to floats')\n",
    "    print('processing.....')\n",
    "    for key,value in dataframes.items():\n",
    "        value = value.apply(pd.to_numeric, errors=\"coerce\")  # Convert to float, set errors as NaN\n",
    "        dataframes[key] = value    \n",
    "        print(f'{key} has been converted')\n",
    "convert_data_types ()       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "PS1.txt is already at 100 Hz, no resampling needed.\n",
      "TS4.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "PS2.txt is already at 100 Hz, no resampling needed.\n",
      "PS3.txt is already at 100 Hz, no resampling needed.\n",
      "TS3.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "VS1.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "TS2.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "PS6.txt is already at 100 Hz, no resampling needed.\n",
      "PS4.txt is already at 100 Hz, no resampling needed.\n",
      "TS1.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "PS5.txt is already at 100 Hz, no resampling needed.\n",
      "CP.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "CE.txt resampled from 60 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "EPS1.txt is already at 100 Hz, no resampling needed.\n",
      "FS1.txt resampled from 600 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "FS2.txt resampled from 600 to 6000 columns.\n",
      "New shape: (2205, 6000)\n",
      "Skipping profile.txt\n"
     ]
    }
   ],
   "source": [
    "def resample_to_100Hz():\n",
    "    \"\"\"\n",
    "    Resamples multiple datasets to 100 Hz (6000 columns), except 'profile.txt'.\n",
    "\n",
    "    Parameters:\n",
    "    dataframes (dict): Dictionary where:\n",
    "        - Keys = dataset names (e.g., \"cooler\", \"valve\", \"pump\")\n",
    "        - Values = DataFrames (Rows = Cycle numbers, Columns = Time intervals)\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary with resampled DataFrames.\n",
    "    \"\"\"\n",
    "    resampled_data = {}  # Dictionary to store resampled datasets\n",
    "    target_columns = 6000  # Standardized column size for 100Hz\n",
    "\n",
    "    for key, df in dataframes.items():\n",
    "        if key == 'profile.txt':  # Skip this dataset\n",
    "            print(f\"Skipping {key}\")\n",
    "            resampled_data[key] = df\n",
    "            continue\n",
    "\n",
    "        num_original_columns = df.shape[1]  # Get current number of time steps\n",
    "\n",
    "        if num_original_columns == target_columns:\n",
    "            print(f\"{key} is already at 100 Hz, no resampling needed.\")\n",
    "            resampled_data[key] = df  # Keep original data\n",
    "            continue\n",
    "\n",
    "        # Create time indices for interpolation\n",
    "        old_index = np.linspace(0, 1, num_original_columns)  # Original time scale\n",
    "        new_index = np.linspace(0, 1, target_columns)  # Target time scale (6000 points)\n",
    "\n",
    "        # Apply cubic interpolation for each row (cycle)\n",
    "        resampled_df = pd.DataFrame(\n",
    "            np.array([np.interp(new_index, old_index, row) for row in df.values]),\n",
    "            index=df.index  # Keep original cycle numbers\n",
    "        )\n",
    "\n",
    "        resampled_data[key] = resampled_df  # Store resampled data\n",
    "        print(f\"{key} resampled from {num_original_columns} to {target_columns} columns.\")\n",
    "        print(f\"New shape: {resampled_df.shape}\")\n",
    "\n",
    "    return resampled_data  # Return resampled dictionary\n",
    "dataframes = resample_to_100Hz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 2205 rows into Cycle table\n",
      "Inserted 12 rows into Sensor table.\n",
      "Inserted 2205 rows into Stable_Efficiency\n",
      "Inserted 2205 rows into Pressure\n",
      "Inserted 2205 rows into Temperature\n",
      "Inserted 2205 rows into Pressure\n",
      "Inserted 2205 rows into Pressure\n",
      "Inserted 2205 rows into Temperature\n",
      "Inserted 2205 rows into Vibration_Sensor\n",
      "Inserted 2205 rows into Temperature\n",
      "Inserted 2205 rows into Pressure\n",
      "Inserted 2205 rows into Pressure\n",
      "Inserted 2205 rows into Temperature\n",
      "Inserted 2205 rows into Pressure\n",
      "Inserted 2205 rows into Cooling_Power\n",
      "Inserted 2205 rows into Cooling_Efficiency\n",
      "Inserted 2205 rows into Efficiency_Power_Signal\n",
      "Inserted 2205 rows into Flow_Sensor\n",
      "Inserted 2205 rows into Flow_Sensor\n",
      "Inserted 2205 rows into Profile table.\n"
     ]
    }
   ],
   "source": [
    "def load_data_into_DB():\n",
    "    # PostgreSQL Connection\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"predictive_maintenance\",\n",
    "        user=\"postgres\",\n",
    "        password=\"20151102\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5433\"\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    table_mapping = {\n",
    "        \"TS1.txt\": \"Temperature\",\n",
    "        \"TS2.txt\": \"Temperature\",\n",
    "        \"TS3.txt\": \"Temperature\",\n",
    "        \"TS4.txt\": \"Temperature\",\n",
    "        \"PS1.txt\": \"Pressure\",\n",
    "        \"PS2.txt\": \"Pressure\",\n",
    "        \"PS3.txt\": \"Pressure\",\n",
    "        \"PS4.txt\": \"Pressure\",\n",
    "        \"PS5.txt\": \"Pressure\",\n",
    "        \"PS6.txt\": \"Pressure\",\n",
    "        \"FS1.txt\": \"Flow_Sensor\",\n",
    "        \"FS2.txt\": \"Flow_Sensor\",\n",
    "        \"CE.txt\": \"Cooling_Efficiency\",\n",
    "        \"SE.txt\": \"Stable_Efficiency\",\n",
    "        \"CP.txt\": \"Cooling_Power\",\n",
    "        \"EPS1.txt\": \"Efficiency_Power_Signal\",\n",
    "        \"VS1.txt\": \"Vibration_Sensor\",\n",
    "        \"profile.txt\": \"Profile\"\n",
    "    }\n",
    "\n",
    "    # Sensor Mapping (Assign SensorIDs)\n",
    "    sensor_mapping = {\n",
    "        \"TS1.txt\": 1, \"TS2.txt\": 2, \"TS3.txt\": 3, \"TS4.txt\": 4,\n",
    "        \"PS1.txt\": 5, \"PS2.txt\": 6, \"PS3.txt\": 7, \"PS4.txt\": 8, \"PS5.txt\": 9, \"PS6.txt\": 10,\n",
    "        \"FS1.txt\": 11, \"FS2.txt\": 12\n",
    "    }\n",
    "\n",
    "\n",
    "    # Step 2: Populate Cycle Table\n",
    "    max_cycles = max(len(df) for df in dataframes.values())  # Find max number of cycles\n",
    "    cur.executemany(\"INSERT INTO Cycle (CycleID) VALUES (%s) ON CONFLICT DO NOTHING;\", [(i,) for i in range(1, max_cycles + 1)])\n",
    "    conn.commit()\n",
    "    print(f\"Inserted {max_cycles} rows into Cycle table\")\n",
    "\n",
    "    # Step 1: Populate the Sensor Table First**\n",
    "    sensor_values = [(s_id, s_type) for s_type, s_id in sensor_mapping.items()]\n",
    "    cur.executemany(\n",
    "        \"INSERT INTO Sensor (SensorID, Sensor_type) VALUES (%s, %s) ON CONFLICT DO NOTHING\",\n",
    "        sensor_values\n",
    "    )\n",
    "    conn.commit()\n",
    "    print(f\"Inserted {len(sensor_values)} rows into Sensor table.\")\n",
    "\n",
    "    # Step 3: Populate the Profile Table\n",
    "\n",
    "\n",
    "    # Step 2: Insert Data into Tables\n",
    "    for key, df in dataframes.items():\n",
    "        if key != 'profile.txt':\n",
    "            table_name = table_mapping[key]  # Convert filename to table name\n",
    "            \n",
    "\n",
    "            # Sensor-based tables (Temperature, Pressure, Flow_Sensor)\n",
    "            if key in sensor_mapping:\n",
    "                sensor_id = sensor_mapping[key]\n",
    "                values = [\n",
    "                    (idx, sensor_id, json.dumps({str(int(k.lstrip(\"_\")) + 1): v for k, v in row._asdict().items()}))  # Convert row to JSON\n",
    "                    for idx, row in enumerate(df.itertuples(index=False), start=1)  # Use row index as CycleID\n",
    "                ]\n",
    "                \n",
    "                insert_query = f\"\"\"\n",
    "                INSERT INTO {table_name} (CycleID, SensorID, {table_name}_data) VALUES (%s, %s, %s)\n",
    "                \"\"\"\n",
    "                cur.executemany(insert_query, values)\n",
    "                conn.commit()\n",
    "                print(f\"Inserted {len(values)} rows into {table_name}\")\n",
    "\n",
    "            # Non-Sensor tables\n",
    "            else:\n",
    "                values = [\n",
    "                    (idx, json.dumps({str(int(k.lstrip(\"_\")) + 1): v for k, v in row._asdict().items()}))\n",
    "                    for idx, row in enumerate(df.itertuples(index=False), start=1)\n",
    "                ]\n",
    "                \n",
    "                insert_query = f\"\"\"\n",
    "                INSERT INTO {table_name} (CycleID, {table_name}_data) VALUES (%s, %s)\n",
    "                \"\"\"\n",
    "                cur.executemany(insert_query, values)\n",
    "                conn.commit()\n",
    "                print(f\"Inserted {len(values)} rows into {table_name}\")\n",
    "        else:\n",
    "            values = [\n",
    "            (\n",
    "            idx,  # CycleID (assuming df_profile rows align with CycleID)\n",
    "            int(row.Cooler_Condition),\n",
    "            int(row.Valve_Condition),\n",
    "            int(row.Pump_Leakage),\n",
    "            int(row.Accumulator_Condition),\n",
    "            bool(row.Stable_Flag)  # Convert to boolean\n",
    "            )\n",
    "            for idx, row in enumerate(df.itertuples(index=False), start=1)\n",
    "            ]\n",
    "\n",
    "            # SQL Insert Query\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO Profile (CycleID, Cooler_Condition, Valve_Condition, Pump_Leakage, Accumulator_Condition, Stable_Flag)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (CycleID) DO NOTHING;\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute insertion\n",
    "            cur.executemany(insert_query, values)\n",
    "            conn.commit()\n",
    "\n",
    "    print(f\"Inserted {len(values)} rows into Profile table.\")        \n",
    "\n",
    "    # Close Connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "load_data_into_DB()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_into_pandas():\n",
    "\n",
    "    # Database connection details\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"predictive_maintenance\",\n",
    "        user=\"postgres\",\n",
    "        password=\"20151102\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5433\"\n",
    "    )\n",
    "\n",
    "    # Connect to PostgreSQL\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Define chunk size\n",
    "    chunk_size = 63\n",
    "    total_rows = 2205\n",
    "    num_chunks = total_rows // chunk_size  # Should be 35 (2205 / 63)\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        offset = i * chunk_size  # Calculate the offset for pagination\n",
    "        query = f\"\"\"\n",
    "            WITH \n",
    "                -- Aggregate Pressure readings by CycleID\n",
    "                Pressure_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Pressure_data) AS Pressure_Readings \n",
    "                    FROM Pressure \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Temperature readings by CycleID\n",
    "                Temperature_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Temperature_data) AS Temperature_Readings \n",
    "                    FROM Temperature \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Flow Sensor readings by CycleID\n",
    "                Flow_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Flow_Sensor_data) AS Flow_Sensor_Readings \n",
    "                    FROM Flow_Sensor \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Stable Efficiency readings by CycleID\n",
    "                Stable_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Stable_Efficiency_data) AS Stable_Efficiency_Readings \n",
    "                    FROM Stable_Efficiency \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Cooling Efficiency readings by CycleID\n",
    "                Cooling_Eff_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Cooling_Efficiency_data) AS Cooling_Efficiency_Readings \n",
    "                    FROM Cooling_Efficiency \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Cooling Power readings by CycleID\n",
    "                Cooling_Power_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Cooling_Power_data) AS Cooling_Power_Readings \n",
    "                    FROM Cooling_Power \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Vibration Sensor readings by CycleID\n",
    "                Vibration_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Vibration_Sensor_data) AS Vibration_Sensor_Readings \n",
    "                    FROM Vibration_Sensor \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                ),\n",
    "\n",
    "                -- Aggregate Efficiency Power Signal readings by CycleID\n",
    "                Efficiency_Agg AS (\n",
    "                    SELECT CycleID, ARRAY_AGG(Efficiency_Power_Signal_data) AS Efficiency_Power_Signal_Readings \n",
    "                    FROM Efficiency_Power_Signal \n",
    "                    GROUP BY CycleID\n",
    "                    ORDER BY CycleID\n",
    "                    LIMIT {chunk_size} OFFSET {offset}\n",
    "                )\n",
    "\n",
    "                SELECT \n",
    "                    c.CycleID,\n",
    "                    p.Pressure_Readings,\n",
    "                    t.Temperature_Readings,\n",
    "                    fs.Flow_Sensor_Readings,\n",
    "                    se.Stable_Efficiency_Readings,\n",
    "                    ce.Cooling_Efficiency_Readings,\n",
    "                    cp.Cooling_Power_Readings,\n",
    "                    vs.Vibration_Sensor_Readings,\n",
    "                    eps.Efficiency_Power_Signal_Readings,\n",
    "                    pf.Cooler_Condition,\n",
    "                    pf.Valve_Condition,\n",
    "                    pf.Pump_Leakage,\n",
    "                    pf.Accumulator_Condition,\n",
    "                    pf.Stable_Flag\n",
    "                FROM Cycle c\n",
    "                INNER JOIN Pressure_Agg p ON c.CycleID = p.CycleID\n",
    "                INNER JOIN Temperature_Agg t ON c.CycleID = t.CycleID\n",
    "                INNER JOIN Flow_Agg fs ON c.CycleID = fs.CycleID\n",
    "                INNER JOIN Stable_Agg se ON c.CycleID = se.CycleID\n",
    "                INNER JOIN Cooling_Eff_Agg ce ON c.CycleID = ce.CycleID\n",
    "                INNER JOIN Cooling_Power_Agg cp ON c.CycleID = cp.CycleID\n",
    "                INNER JOIN Vibration_Agg vs ON c.CycleID = vs.CycleID\n",
    "                INNER JOIN Efficiency_Agg eps ON c.CycleID = eps.CycleID\n",
    "                INNER JOIN Profile pf ON c.CycleID = pf.CycleID;\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute query\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch data\n",
    "        colnames = [desc[0] for desc in cursor.description]  # Get column names\n",
    "        rows = cursor.fetchall()  # Get results\n",
    "        \n",
    "        # Convert chunk to Pandas DataFrame\n",
    "        chunk_df = pd.DataFrame(rows, columns=colnames)\n",
    "        chunks.append(chunk_df)\n",
    "        print(f'dataframe {i+1} has been loaded successfully')\n",
    "\n",
    "    # Merge all chunks into a single DataFrame\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "    # Verify row count\n",
    "    assert df.shape[0] == total_rows, f\"Expected {total_rows} rows, got {df.shape[0]}\"\n",
    "\n",
    "    # Close connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe 1 has been loaded successfully\n",
      "dataframe 2 has been loaded successfully\n",
      "dataframe 3 has been loaded successfully\n",
      "dataframe 4 has been loaded successfully\n",
      "dataframe 5 has been loaded successfully\n",
      "dataframe 6 has been loaded successfully\n",
      "dataframe 7 has been loaded successfully\n",
      "dataframe 8 has been loaded successfully\n",
      "dataframe 9 has been loaded successfully\n",
      "dataframe 10 has been loaded successfully\n",
      "dataframe 11 has been loaded successfully\n",
      "dataframe 12 has been loaded successfully\n",
      "dataframe 13 has been loaded successfully\n",
      "dataframe 14 has been loaded successfully\n",
      "dataframe 15 has been loaded successfully\n",
      "dataframe 16 has been loaded successfully\n",
      "dataframe 17 has been loaded successfully\n",
      "dataframe 18 has been loaded successfully\n",
      "dataframe 19 has been loaded successfully\n",
      "dataframe 20 has been loaded successfully\n",
      "dataframe 21 has been loaded successfully\n",
      "dataframe 22 has been loaded successfully\n",
      "dataframe 23 has been loaded successfully\n",
      "dataframe 24 has been loaded successfully\n",
      "dataframe 25 has been loaded successfully\n",
      "dataframe 26 has been loaded successfully\n",
      "dataframe 27 has been loaded successfully\n",
      "dataframe 28 has been loaded successfully\n",
      "dataframe 29 has been loaded successfully\n",
      "dataframe 30 has been loaded successfully\n",
      "dataframe 31 has been loaded successfully\n",
      "dataframe 32 has been loaded successfully\n",
      "dataframe 33 has been loaded successfully\n",
      "dataframe 34 has been loaded successfully\n",
      "dataframe 35 has been loaded successfully\n"
     ]
    }
   ],
   "source": [
    "df = load_into_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressure_readings                   [{'1': 151.24, '2': 151.24, '3': 151.19, '4': ...\n",
       "temperature_readings                [{'1': 30.621, '2': 30.62096066011002, '3': 30...\n",
       "flow_sensor_readings                [{'1': 7.918, '2': 7.249504417402901, '3': 6.5...\n",
       "stable_efficiency_readings          [{'1': 65.94, '2': 65.29148191365228, '3': 64....\n",
       "cooling_efficiency_readings         [{'1': 46.376, '2': 46.376, '3': 46.376, '4': ...\n",
       "cooling_power_readings              [{'1': 2.135, '2': 2.1350688448074675, '3': 2....\n",
       "vibration_sensor_readings           [{'1': 0.552, '2': 0.5521475245874313, '3': 0....\n",
       "efficiency_power_signal_readings    [{'1': 2417.6, '2': 2417.8, '3': 2417.8, '4': ...\n",
       "cooler_condition                                                                  100\n",
       "valve_condition                                                                   100\n",
       "pump_leakage                                                                        0\n",
       "accumulator_condition                                                              90\n",
       "stable_flag                                                                      True\n",
       "Name: 2156, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stable = df[df['stable_flag']==True]\n",
    "df_stable_reindexed = df_stable.set_index('cycleid')\n",
    "df_stable_reindexed.loc[2156]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 756 entries, 1 to 2156\n",
      "Data columns (total 13 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   pressure_readings                 756 non-null    object\n",
      " 1   temperature_readings              756 non-null    object\n",
      " 2   flow_sensor_readings              756 non-null    object\n",
      " 3   stable_efficiency_readings        756 non-null    object\n",
      " 4   cooling_efficiency_readings       756 non-null    object\n",
      " 5   cooling_power_readings            756 non-null    object\n",
      " 6   vibration_sensor_readings         756 non-null    object\n",
      " 7   efficiency_power_signal_readings  756 non-null    object\n",
      " 8   cooler_condition                  756 non-null    int64 \n",
      " 9   valve_condition                   756 non-null    int64 \n",
      " 10  pump_leakage                      756 non-null    int64 \n",
      " 11  accumulator_condition             756 non-null    int64 \n",
      " 12  stable_flag                       756 non-null    bool  \n",
      "dtypes: bool(1), int64(4), object(8)\n",
      "memory usage: 77.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_stable_reindexed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressure_readings                   0\n",
       "temperature_readings                0\n",
       "flow_sensor_readings                0\n",
       "stable_efficiency_readings          0\n",
       "cooling_efficiency_readings         0\n",
       "cooling_power_readings              0\n",
       "vibration_sensor_readings           0\n",
       "efficiency_power_signal_readings    0\n",
       "cooler_condition                    0\n",
       "valve_condition                     0\n",
       "pump_leakage                        0\n",
       "accumulator_condition               0\n",
       "stable_flag                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stable_reindexed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure_readings</th>\n",
       "      <th>temperature_readings</th>\n",
       "      <th>flow_sensor_readings</th>\n",
       "      <th>stable_efficiency_readings</th>\n",
       "      <th>cooling_efficiency_readings</th>\n",
       "      <th>cooling_power_readings</th>\n",
       "      <th>vibration_sensor_readings</th>\n",
       "      <th>efficiency_power_signal_readings</th>\n",
       "      <th>cooler_condition</th>\n",
       "      <th>valve_condition</th>\n",
       "      <th>pump_leakage</th>\n",
       "      <th>accumulator_condition</th>\n",
       "      <th>stable_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycleid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'1': 151.47, '2': 151.45, '3': 151.52, '4': ...</td>\n",
       "      <td>[{'1': 30.363, '2': 30.363118019669944, '3': 3...</td>\n",
       "      <td>[{'1': 8.99, '2': 8.169233205534256, '3': 7.34...</td>\n",
       "      <td>[{'1': 68.039, '2': 67.3698383063844, '3': 66....</td>\n",
       "      <td>[{'1': 47.202, '2': 47.20269828304717, '3': 47...</td>\n",
       "      <td>[{'1': 2.184, '2': 2.184, '3': 2.184, '4': 2.1...</td>\n",
       "      <td>[{'1': 0.604, '2': 0.6040098349724954, '3': 0....</td>\n",
       "      <td>[{'1': 2411.6, '2': 2411.6, '3': 2411.6, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'1': 151.11, '2': 151.12, '3': 151.16, '4': ...</td>\n",
       "      <td>[{'1': 33.648, '2': 33.64873762293716, '3': 33...</td>\n",
       "      <td>[{'1': 8.919, '2': 8.109815802633772, '3': 7.3...</td>\n",
       "      <td>[{'1': 68.264, '2': 67.59262543757292, '3': 66...</td>\n",
       "      <td>[{'1': 29.208, '2': 29.20420370061677, '3': 29...</td>\n",
       "      <td>[{'1': 1.414, '2': 1.4137049508251374, '3': 1....</td>\n",
       "      <td>[{'1': 0.59, '2': 0.5901966994499083, '3': 0.5...</td>\n",
       "      <td>[{'1': 2409.6, '2': 2409.6, '3': 2409.6, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'1': 150.81, '2': 150.79, '3': 150.84, '4': ...</td>\n",
       "      <td>[{'1': 35.113, '2': 35.11307867977996, '3': 35...</td>\n",
       "      <td>[{'1': 9.179, '2': 8.330674612435406, '3': 7.4...</td>\n",
       "      <td>[{'1': 68.595, '2': 67.92037006167695, '3': 67...</td>\n",
       "      <td>[{'1': 23.554, '2': 23.55367544590765, '3': 23...</td>\n",
       "      <td>[{'1': 1.159, '2': 1.1589803300550092, '3': 1....</td>\n",
       "      <td>[{'1': 0.578, '2': 0.5782458743123854, '3': 0....</td>\n",
       "      <td>[{'1': 2397.8, '2': 2397.8, '3': 2397.8, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'1': 150.48, '2': 150.47, '3': 150.52, '4': ...</td>\n",
       "      <td>[{'1': 36.133, '2': 36.132724620770134, '3': 3...</td>\n",
       "      <td>[{'1': 9.034, '2': 8.204646107684615, '3': 7.3...</td>\n",
       "      <td>[{'1': 68.628, '2': 67.95304550758459, '3': 67...</td>\n",
       "      <td>[{'1': 21.54, '2': 21.538809968328053, '3': 21...</td>\n",
       "      <td>[{'1': 1.101, '2': 1.1008524754125688, '3': 1....</td>\n",
       "      <td>[{'1': 0.565, '2': 0.5652557092848808, '3': 0....</td>\n",
       "      <td>[{'1': 2383.8, '2': 2383.8, '3': 2383.8, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'1': 150.41, '2': 150.35, '3': 150.24, '4': ...</td>\n",
       "      <td>[{'1': 36.992, '2': 36.992118019669945, '3': 3...</td>\n",
       "      <td>[{'1': 8.729, '2': 7.927803800633439, '3': 7.1...</td>\n",
       "      <td>[{'1': 68.868, '2': 68.1906851141857, '3': 67....</td>\n",
       "      <td>[{'1': 20.46, '2': 20.458406734455743, '3': 20...</td>\n",
       "      <td>[{'1': 1.086, '2': 1.085950825137523, '3': 1.0...</td>\n",
       "      <td>[{'1': 0.57, '2': 0.5702950491748624, '3': 0.5...</td>\n",
       "      <td>[{'1': 2372.0, '2': 2372.0, '3': 2372.0, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[{'1': 150.27, '2': 150.2, '3': 150.16, '4': 1...</td>\n",
       "      <td>[{'1': 37.824, '2': 37.824157359559926, '3': 3...</td>\n",
       "      <td>[{'1': 9.044, '2': 8.213248208034672, '3': 7.3...</td>\n",
       "      <td>[{'1': 68.972, '2': 68.29366227704617, '3': 67...</td>\n",
       "      <td>[{'1': 19.651, '2': 19.65084264044007, '3': 19...</td>\n",
       "      <td>[{'1': 1.083, '2': 1.083049174862477, '3': 1.0...</td>\n",
       "      <td>[{'1': 0.568, '2': 0.5683245540923487, '3': 0....</td>\n",
       "      <td>[{'1': 2369.6, '2': 2369.6, '3': 2369.6, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[{'1': 149.92, '2': 149.87, '3': 149.96, '4': ...</td>\n",
       "      <td>[{'1': 38.566, '2': 38.56596066011002, '3': 38...</td>\n",
       "      <td>[{'1': 9.393, '2': 8.528998166361061, '3': 7.6...</td>\n",
       "      <td>[{'1': 68.512, '2': 67.83818636439406, '3': 67...</td>\n",
       "      <td>[{'1': 19.339, '2': 19.33974745790965, '3': 19...</td>\n",
       "      <td>[{'1': 1.11, '2': 1.1099901650275046, '3': 1.1...</td>\n",
       "      <td>[{'1': 0.582, '2': 0.5822262043673945, '3': 0....</td>\n",
       "      <td>[{'1': 2369.8, '2': 2369.0, '3': 2368.8, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[{'1': 149.72, '2': 149.82, '3': 149.89, '4': ...</td>\n",
       "      <td>[{'1': 39.227, '2': 39.22787531255209, '3': 39...</td>\n",
       "      <td>[{'1': 9.109, '2': 8.27615135855976, '3': 7.44...</td>\n",
       "      <td>[{'1': 68.566, '2': 67.89165527587932, '3': 67...</td>\n",
       "      <td>[{'1': 18.788, '2': 18.78433155525921, '3': 18...</td>\n",
       "      <td>[{'1': 1.102, '2': 1.1018229704950826, '3': 1....</td>\n",
       "      <td>[{'1': 0.583, '2': 0.5833048841473578, '3': 0....</td>\n",
       "      <td>[{'1': 2355.8, '2': 2355.8, '3': 2355.8, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[{'1': 149.82, '2': 149.87, '3': 150.01, '4': ...</td>\n",
       "      <td>[{'1': 39.793, '2': 39.793, '3': 39.793, '4': ...</td>\n",
       "      <td>[{'1': 9.244, '2': 8.396373562260377, '3': 7.5...</td>\n",
       "      <td>[{'1': 68.697, '2': 68.02136689448241, '3': 67...</td>\n",
       "      <td>[{'1': 18.362, '2': 18.3624229038173, '3': 18....</td>\n",
       "      <td>[{'1': 1.103, '2': 1.103, '3': 1.103, '4': 1.1...</td>\n",
       "      <td>[{'1': 0.57, '2': 0.5702458743123854, '3': 0.5...</td>\n",
       "      <td>[{'1': 2354.0, '2': 2354.0, '3': 2354.0, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[{'1': 149.68, '2': 149.66, '3': 149.71, '4': ...</td>\n",
       "      <td>[{'1': 40.379, '2': 40.37907867977996, '3': 40...</td>\n",
       "      <td>[{'1': 9.412, '2': 8.557783463910653, '3': 7.7...</td>\n",
       "      <td>[{'1': 68.854, '2': 68.17682280380063, '3': 67...</td>\n",
       "      <td>[{'1': 18.201, '2': 18.201550758459742, '3': 1...</td>\n",
       "      <td>[{'1': 1.122, '2': 1.122019669944991, '3': 1.1...</td>\n",
       "      <td>[{'1': 0.578, '2': 0.5782655442573762, '3': 0....</td>\n",
       "      <td>[{'1': 2349.8, '2': 2349.8, '3': 2349.8, '4': ...</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         pressure_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 151.47, '2': 151.45, '3': 151.52, '4': ...   \n",
       "2        [{'1': 151.11, '2': 151.12, '3': 151.16, '4': ...   \n",
       "3        [{'1': 150.81, '2': 150.79, '3': 150.84, '4': ...   \n",
       "4        [{'1': 150.48, '2': 150.47, '3': 150.52, '4': ...   \n",
       "5        [{'1': 150.41, '2': 150.35, '3': 150.24, '4': ...   \n",
       "6        [{'1': 150.27, '2': 150.2, '3': 150.16, '4': 1...   \n",
       "7        [{'1': 149.92, '2': 149.87, '3': 149.96, '4': ...   \n",
       "8        [{'1': 149.72, '2': 149.82, '3': 149.89, '4': ...   \n",
       "9        [{'1': 149.82, '2': 149.87, '3': 150.01, '4': ...   \n",
       "10       [{'1': 149.68, '2': 149.66, '3': 149.71, '4': ...   \n",
       "\n",
       "                                      temperature_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 30.363, '2': 30.363118019669944, '3': 3...   \n",
       "2        [{'1': 33.648, '2': 33.64873762293716, '3': 33...   \n",
       "3        [{'1': 35.113, '2': 35.11307867977996, '3': 35...   \n",
       "4        [{'1': 36.133, '2': 36.132724620770134, '3': 3...   \n",
       "5        [{'1': 36.992, '2': 36.992118019669945, '3': 3...   \n",
       "6        [{'1': 37.824, '2': 37.824157359559926, '3': 3...   \n",
       "7        [{'1': 38.566, '2': 38.56596066011002, '3': 38...   \n",
       "8        [{'1': 39.227, '2': 39.22787531255209, '3': 39...   \n",
       "9        [{'1': 39.793, '2': 39.793, '3': 39.793, '4': ...   \n",
       "10       [{'1': 40.379, '2': 40.37907867977996, '3': 40...   \n",
       "\n",
       "                                      flow_sensor_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 8.99, '2': 8.169233205534256, '3': 7.34...   \n",
       "2        [{'1': 8.919, '2': 8.109815802633772, '3': 7.3...   \n",
       "3        [{'1': 9.179, '2': 8.330674612435406, '3': 7.4...   \n",
       "4        [{'1': 9.034, '2': 8.204646107684615, '3': 7.3...   \n",
       "5        [{'1': 8.729, '2': 7.927803800633439, '3': 7.1...   \n",
       "6        [{'1': 9.044, '2': 8.213248208034672, '3': 7.3...   \n",
       "7        [{'1': 9.393, '2': 8.528998166361061, '3': 7.6...   \n",
       "8        [{'1': 9.109, '2': 8.27615135855976, '3': 7.44...   \n",
       "9        [{'1': 9.244, '2': 8.396373562260377, '3': 7.5...   \n",
       "10       [{'1': 9.412, '2': 8.557783463910653, '3': 7.7...   \n",
       "\n",
       "                                stable_efficiency_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 68.039, '2': 67.3698383063844, '3': 66....   \n",
       "2        [{'1': 68.264, '2': 67.59262543757292, '3': 66...   \n",
       "3        [{'1': 68.595, '2': 67.92037006167695, '3': 67...   \n",
       "4        [{'1': 68.628, '2': 67.95304550758459, '3': 67...   \n",
       "5        [{'1': 68.868, '2': 68.1906851141857, '3': 67....   \n",
       "6        [{'1': 68.972, '2': 68.29366227704617, '3': 67...   \n",
       "7        [{'1': 68.512, '2': 67.83818636439406, '3': 67...   \n",
       "8        [{'1': 68.566, '2': 67.89165527587932, '3': 67...   \n",
       "9        [{'1': 68.697, '2': 68.02136689448241, '3': 67...   \n",
       "10       [{'1': 68.854, '2': 68.17682280380063, '3': 67...   \n",
       "\n",
       "                               cooling_efficiency_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 47.202, '2': 47.20269828304717, '3': 47...   \n",
       "2        [{'1': 29.208, '2': 29.20420370061677, '3': 29...   \n",
       "3        [{'1': 23.554, '2': 23.55367544590765, '3': 23...   \n",
       "4        [{'1': 21.54, '2': 21.538809968328053, '3': 21...   \n",
       "5        [{'1': 20.46, '2': 20.458406734455743, '3': 20...   \n",
       "6        [{'1': 19.651, '2': 19.65084264044007, '3': 19...   \n",
       "7        [{'1': 19.339, '2': 19.33974745790965, '3': 19...   \n",
       "8        [{'1': 18.788, '2': 18.78433155525921, '3': 18...   \n",
       "9        [{'1': 18.362, '2': 18.3624229038173, '3': 18....   \n",
       "10       [{'1': 18.201, '2': 18.201550758459742, '3': 1...   \n",
       "\n",
       "                                    cooling_power_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 2.184, '2': 2.184, '3': 2.184, '4': 2.1...   \n",
       "2        [{'1': 1.414, '2': 1.4137049508251374, '3': 1....   \n",
       "3        [{'1': 1.159, '2': 1.1589803300550092, '3': 1....   \n",
       "4        [{'1': 1.101, '2': 1.1008524754125688, '3': 1....   \n",
       "5        [{'1': 1.086, '2': 1.085950825137523, '3': 1.0...   \n",
       "6        [{'1': 1.083, '2': 1.083049174862477, '3': 1.0...   \n",
       "7        [{'1': 1.11, '2': 1.1099901650275046, '3': 1.1...   \n",
       "8        [{'1': 1.102, '2': 1.1018229704950826, '3': 1....   \n",
       "9        [{'1': 1.103, '2': 1.103, '3': 1.103, '4': 1.1...   \n",
       "10       [{'1': 1.122, '2': 1.122019669944991, '3': 1.1...   \n",
       "\n",
       "                                 vibration_sensor_readings  \\\n",
       "cycleid                                                      \n",
       "1        [{'1': 0.604, '2': 0.6040098349724954, '3': 0....   \n",
       "2        [{'1': 0.59, '2': 0.5901966994499083, '3': 0.5...   \n",
       "3        [{'1': 0.578, '2': 0.5782458743123854, '3': 0....   \n",
       "4        [{'1': 0.565, '2': 0.5652557092848808, '3': 0....   \n",
       "5        [{'1': 0.57, '2': 0.5702950491748624, '3': 0.5...   \n",
       "6        [{'1': 0.568, '2': 0.5683245540923487, '3': 0....   \n",
       "7        [{'1': 0.582, '2': 0.5822262043673945, '3': 0....   \n",
       "8        [{'1': 0.583, '2': 0.5833048841473578, '3': 0....   \n",
       "9        [{'1': 0.57, '2': 0.5702458743123854, '3': 0.5...   \n",
       "10       [{'1': 0.578, '2': 0.5782655442573762, '3': 0....   \n",
       "\n",
       "                          efficiency_power_signal_readings  cooler_condition  \\\n",
       "cycleid                                                                        \n",
       "1        [{'1': 2411.6, '2': 2411.6, '3': 2411.6, '4': ...                 3   \n",
       "2        [{'1': 2409.6, '2': 2409.6, '3': 2409.6, '4': ...                 3   \n",
       "3        [{'1': 2397.8, '2': 2397.8, '3': 2397.8, '4': ...                 3   \n",
       "4        [{'1': 2383.8, '2': 2383.8, '3': 2383.8, '4': ...                 3   \n",
       "5        [{'1': 2372.0, '2': 2372.0, '3': 2372.0, '4': ...                 3   \n",
       "6        [{'1': 2369.6, '2': 2369.6, '3': 2369.6, '4': ...                 3   \n",
       "7        [{'1': 2369.8, '2': 2369.0, '3': 2368.8, '4': ...                 3   \n",
       "8        [{'1': 2355.8, '2': 2355.8, '3': 2355.8, '4': ...                 3   \n",
       "9        [{'1': 2354.0, '2': 2354.0, '3': 2354.0, '4': ...                 3   \n",
       "10       [{'1': 2349.8, '2': 2349.8, '3': 2349.8, '4': ...                 3   \n",
       "\n",
       "         valve_condition  pump_leakage  accumulator_condition  stable_flag  \n",
       "cycleid                                                                     \n",
       "1                    100             0                    130         True  \n",
       "2                    100             0                    130         True  \n",
       "3                    100             0                    130         True  \n",
       "4                    100             0                    130         True  \n",
       "5                    100             0                    130         True  \n",
       "6                    100             0                    130         True  \n",
       "7                    100             0                    130         True  \n",
       "8                    100             0                    130         True  \n",
       "9                    100             0                    130         True  \n",
       "10                   100             0                    130         True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stable_reindexed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    }
   ],
   "source": [
    "print(len(df_stable_reindexed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_columns():\n",
    "    for column_name in df_stable_reindexed:\n",
    "        if df_stable_reindexed[column_name].apply(lambda x: isinstance(x, list)).all():\n",
    "            # Get the number of dictionaries in the first row (assuming all rows have the same structure)\n",
    "            num_dicts = df_stable_reindexed[column_name].apply(len).unique()[0]\n",
    "            df_stable_reindexed[[f'{column_name}_{i}' for i in range(1,num_dicts+1)]] = pd.DataFrame(df_stable_reindexed[column_name].tolist(),index = df_stable_reindexed.index)\n",
    "            df_stable_reindexed.drop(columns=[column_name],inplace=True)        \n",
    "split_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756, 22)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63c49e8d1e646aa190844836d1cfc5ee1f530ae32fef9584fc84302df7dcdbd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
